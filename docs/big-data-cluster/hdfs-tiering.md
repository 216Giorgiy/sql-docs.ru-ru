---
title: Настроить распределение по уровням HDFS
titleSuffix: SQL Server 2019 big data clusters
description: В этой статье описывается настройка HDFS, распределение по уровням для монтажа внешней системы хранилище Azure Data Lake файл в HDFS в кластере SQL Server 2019 больших данных (Предварительная версия).
author: nelgson
ms.author: negust
ms.reviewer: jroth
manager: craigg
ms.date: 03/27/2018
ms.topic: conceptual
ms.prod: sql
ms.technology: big-data-cluster
ms.openlocfilehash: 1199d8d522df83c626f04f30c8937b57a5359f5c
ms.sourcegitcommit: 2db83830514d23691b914466a314dfeb49094b3c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2019
ms.locfileid: "58493781"
---
# <a name="configure-hdfs-tiering-on-sql-server-2019-big-data-clusters"></a>Настройка HDFS, распределение по уровням в кластерах SQL Server 2019 больших данных

Распределение по уровням HDFS позволяет подключать внешние, HDFS-совместимой файловой системы в HDFS. В этой статье описывается настройка HDFS, распределение по уровням для кластеров SQL Server 2019 больших данных (Предварительная версия). В настоящее время CTP-версии 2.4 поддерживает только подключение к Azure Data Lake хранилища 2-го поколения, которое рассматривается в этой статье.

## <a name="hdfs-tiering-overview"></a>Обзор распределения по уровням HDFS

С уровнями, приложения могут легко обращаться к данным в различных внешних хранилищ так, будто они находятся в файловой системе HDFS. Подключение — это операция с метаданными, где метаданные, описывающие пространство имен внешней файловой системе, копируются в HDFS. К метаданным относятся сведения о внешних каталогов и файлов вместе с их разрешениями и списками ACL. Соответствующие данные — только скопированный по требованию, при обращении к самим данным. Данные внешней файловой системы, теперь может осуществляться из больших данных кластера SQL Server. Можно запустить Spark задания и запросы SQL, на основе этих данных таким же образом, необходимо выполнить их на все локальные данные, хранящиеся в файловой системе HDFS в кластере.

> [!NOTE]
> Распределение по уровням HDFS — это функция, разработанная корпорацией Майкрософт и более ранняя версия была выпущена в виде части распространения Apache Hadoop 3.1. Дополнительные сведения см. в разделе [ https://issues.apache.org/jira/browse/HDFS-9806 ](https://issues.apache.org/jira/browse/HDFS-9806) сведения.

Следующие разделы содержат пример, демонстрирующий настройку HDFS, распределение по уровням с источником данных Gen2 хранилища Озера данных Azure.

## <a name="prerequisites"></a>предварительные требования

- [Развернутые больших данных кластера](deployment-guidance.md)
- [Средства работы с большими данными](deploy-big-data-tools.md)
  - **mssqlctl**
  - **kubectl**

## <a id="load"></a> Загрузка данных в хранилище Azure Data Lake

Следующий раздел описывает способы настройки Gen2 хранилища Озера данных Azure для тестирования HDFS распределение по уровням. Если у вас уже есть данные, хранящиеся в хранилище Azure Data Lake, можно пропустить этот раздел, чтобы использовать собственные данные.

1. [Создание учетной записи хранения с помощью возможности Gen2 хранилища Озера данных](https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-quickstart-create-account).

1. [Создайте контейнер больших двоичных объектов](https://docs.microsoft.com/azure/storage/blobs/storage-quickstart-blobs-portal) данной учетной записи хранения для внешних данных.

1. Отправьте файл CSV или Parquet в контейнер. Это внешние данные HDFS, который будет подключен к HDFS в кластере больших данных.

## <a id="mount"></a> Подключение удаленного хранилища HDFS

Следующие действия подключить внешнее хранилище HDFS в Azure Data Lake в локальное хранилище HDFS кластера больших данных.

1. Откройте командную строку на клиентском компьютере с доступом к кластеру больших данных.

1. Создайте локальный файл с именем **files.creds** , содержащий учетные данные учетной записи Gen2 хранилища Озера данных Azure в следующем формате:

   ```text
   fs.azure.abfs.account.name=<your-storage-account-name>.dfs.core.windows.net
   fs.azure.account.key.<your-storage-account-name>.dfs.core.windows.net=<storage-account-access-key>
   ```

   > [!TIP]
   > Дополнительные сведения о том, как найти ключ доступа (`<storage-account-access-key>`) для учетной записи хранения, см. в разделе [Просмотр и копирование ключей доступа к](https://docs.microsoft.com/azure/storage/common/storage-account-manage?#view-and-copy-access-keys).

1. Используйте **kubectl** найти IP-адрес для **конечная точка службы прокси-сервера** службы в кластере больших данных. Найдите **внешний IP-**.

   ```bash
   kubectl get svc endpoint-service-proxy -n <your-cluster-name>
   ```

1. Входа в систему **mssqlctl** с помощью конечной точки службы прокси-сервера с помощью имени пользователя кластера и пароль:

   ```bash
   mssqlctl login -e https://<IP-of-endpoint-service-proxy>:30777/ -u <username> -p <password>
   ```

1. Подключение удаленного хранилища HDFS в Azure с помощью **создать подключения хранилища mssqlctl**. Замените значения заполнителей перед выполнением следующей команды:

   ```bash
   mssqlctl storage mount create --remote-uri abfs://<blob-container-name>@<storage-account-name>.dfs.core.windows.net/ --mount-path /mounts/<mount-name> --credential-file <path-to-adls-credentials>/file.creds
   ```

   > [!NOTE]
   > Подключения «создать» является асинхронным. В настоящее время отсутствуют сообщения, указывающее, успешно ли выполнено присоединение. См. в разделе [состояние](#status) раздела, чтобы проверить состояние вашей подключение.

В случае если успешно, можно запросить данные HDFS и выполнения заданий Spark на ее основе. Он будет отображаться в HDFS для кластера больших данных в расположении, заданном параметром `--local-path`.

## <a id="status"></a> Получение состояния подключение

Чтобы получить список состояние всех подключение кластера больших данных, используйте следующую команду:

```bash
mssqlctl storage mount status
```

Чтобы получить список состояние подключения в указанную папку в файловой системе HDFS, используйте следующую команду:

```bash
mssqlctl storage mount status --mount-path <mount-path-in-hdfs>
```

## <a id="delete"></a> Удаление подключения

Чтобы удалить подключение, используйте **удаления подключения хранилища mssqlctl** команды и укажите путь подключения в HDFS:

```bash
mssqlctl storage mount delete --mount-path <mount-path-in-hdfs>
```

## <a id="issues"></a> Известные проблемы и ограничения

В следующем списке приведены известные проблемы и текущие ограничения при использовании HDFS, распределение по уровням в кластеры большие данные SQL Server:

- Если размер внешнего каталога монтирования превышает емкость кластера, подключение завершается ошибкой.

- Если подключение зависла в `CREATING` состоянии в течение длительного времени, скорее она выдавала сбой. В этом случае отмена команды и при необходимости удалить подключения. Проверьте параметры и учетные данные перед повторной попыткой.

- Подключение невозможно создать в существующих каталогах.

- Подключение невозможно создать в существующих подключений.

- Если любой из предков точке подключения не существуют, они будут созданы с разрешениями по умолчанию r-xr-xr-x (555).

- Создание подключения может занять некоторое время в зависимости от того, количество и размер файлов, которому выполняется подключение. В ходе этого процесса файлы в папке mount не видны пользователям. В процессе подключения все файлы будут добавляться временный путь, по умолчанию — `/_temporary/_mounts/<mount-location>`.

- Команда создания подключения является асинхронным. После выполнения команды можно проверить состояние подключения для оценки состояния подключения.

- При создании подключения, аргумент используются для **--local-path** — по сути это уникальный идентификатор подключения. В последующих командах необходимо использовать ту же строку (в том числе «/» в конце концов, если он имеется).

- Подключение доступны только для чтения. Не удается создать любой каталогов или файлов в разделе подключения.

- Мы не рекомендуем подключения каталогов и файлов, которые можно изменить. После создания подключения любые изменения или обновления в удаленное расположение не отражаются в подключения в HDFS. Если изменения происходят в удаленном расположении, можно удалять и повторно создавать подключения в соответствии с обновленное состояние.

## <a name="next-steps"></a>Следующие шаги

Дополнительные сведения о кластерах SQL Server 2019 большие данные см. в разделе [Каковы кластеров SQL Server 2019 больших данных?](big-data-cluster-overview.md).
